Input

+----+---------------+
|name|           rank|
+----+---------------+
|   a|   [1, 1, 1, 3]|
|   b|   [1, 2, 3, 4]|
|   c|[1, 1, 1, 1, 4]|
|   d|            [3]|
+----+---------------+

+----+
Expected Output
+----+

+----+
|name|
+----+
|   c|
+----+

Solution

from pyspark import *
from pyspark import SparkConf, SparkContext
from pyspark.sql import *
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
from pyspark.sql.window import *

conf = SparkConf().setMaster("local[*]").setAppName("test")
sc = SparkContext(conf=conf)
sc.setLogLevel("ERROR")

spark = SparkSession.builder.getOrCreate()

data = [

    ("a", [1, 1, 1, 3]),

    ("b", [1, 2, 3, 4]),

    ("c", [1, 1, 1, 1, 4]),

    ("d", [3])

]

df = spark.createDataFrame(data, ["name", "rank"])

df.show()

f=df.withColumn('rank',explode('rank'))

f=f.filter('rank=1')

f=f.groupby('name').agg(count('rank').alias('rank')).orderBy(desc('rank'))

rt=f.agg(max('rank').alias('rank'))

rt.show()

f.join(rt,'rank','inner').drop('rank').show()

# win=Window.orderBy(desc('rank'))
# fin=f.withColumn('dern',dense_rank().over(win))
# fin.show()
# fin.filter("dern=1").drop('dern','rank').show()
 
